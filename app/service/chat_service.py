import json
import logging
import os
import random
import re
import uuid
from openai import AzureOpenAI
from typing import Generator, Dict
from .architecture_diagram_service import ArchitectureDiagramService

azure_openai_endpoint = os.environ.get('AZURE_OPENAI_ENDPOINT')
azure_openai_api_key = os.environ.get('AZURE_OPENAI_API_KEY')
azure_openai_deployment_name = os.environ.get('AZURE_OPENAI_DEPLOYMENT_NAME')
cognitive_search_endpoint = os.environ.get('COGNITIVE_SEARCH_ENDPOINT')
cognitive_search_api_key = os.environ.get('COGNITIVE_SEARCH_API_KEY')
cognitive_search_index_name = os.environ.get('COGNITIVE_SEARCH_INDEX_NAME')

sentence_level_punctuations = ['.', '?', '!', ':', ';', 'ã€‚', 'ï¼Ÿ', 'ï¼', 'ï¼š', 'ï¼›']
enable_quick_reply = False
quick_replies = ['Let me take a look.', 'Let me check.', 'One moment, please.']
oyd_doc_regex = re.compile(r'\[doc(\d+)\]')

# Logger ì„¤ì •
logger = logging.getLogger(__name__)

azure_openai = None
if azure_openai_endpoint and azure_openai_api_key:
    azure_openai = AzureOpenAI(
        azure_endpoint=azure_openai_endpoint,
        api_version='2024-06-01',
        api_key=azure_openai_api_key)


class ChatService:
    
    def __init__(self):
        self.client_contexts = {}
        self.architecture_service = ArchitectureDiagramService()
    
    def set_client_contexts(self, client_contexts: Dict):
        self.client_contexts = client_contexts
    
    def get_system_prompt(self):
        """ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ë°˜í™˜ - LLMì´ JSON í˜•íƒœë¡œ ì‘ë‹µí•˜ë„ë¡ ì§€ì‹œ"""
        return """
ë‹¹ì‹ ì€ Azure ì•„í‚¤í…ì²˜ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ë¶„ì„í•˜ì—¬ ì ì ˆí•œ ì‘ë‹µê³¼ ì•¡ì…˜ì„ ê²°ì •í•´ì£¼ì„¸ìš”.

ì‘ë‹µ í˜•ì‹ì€ ë°˜ë“œì‹œ ë‹¤ìŒ JSON í˜•íƒœì—¬ì•¼ í•©ë‹ˆë‹¤:
{
  "response": "ì‚¬ìš©ìì—ê²Œ ë³´ì—¬ì¤„ ì‘ë‹µ ë©”ì‹œì§€",
  "action": "ìˆ˜í–‰í•  ì•¡ì…˜ (ì•„ë˜ ì¤‘ í•˜ë‚˜ ë˜ëŠ” ë¹ˆ ë¬¸ìì—´)"
}

ê°€ëŠ¥í•œ action ì¢…ë¥˜:
1. "generate_architecture_diagram" - ìƒˆë¡œìš´ ì•„í‚¤í…ì²˜ ë‹¤ì´ì–´ê·¸ë¨ì„ ìƒì„±í•´ì•¼ í•˜ëŠ” ê²½ìš°
2. "modify_architecture_diagram" - ê¸°ì¡´ ì•„í‚¤í…ì²˜ë¥¼ ìˆ˜ì •í•´ì•¼ í•˜ëŠ” ê²½ìš°  
3. "generate_bicep_infrastructure" - Bicep ì¸í”„ë¼ ì½”ë“œë¥¼ ìƒì„±í•´ì•¼ í•˜ëŠ” ê²½ìš°
4. "" (ë¹ˆ ë¬¸ìì—´) - ì¼ë°˜ì ì¸ ì§ˆë¬¸ìœ¼ë¡œ íŠ¹ë³„í•œ ì•¡ì…˜ì´ í•„ìš” ì—†ëŠ” ê²½ìš°

íŒë‹¨ ê¸°ì¤€:
- ì•„í‚¤í…ì²˜ ìƒì„±/ì„¤ê³„ ê´€ë ¨ í‚¤ì›Œë“œ: "ì•„í‚¤í…ì²˜", "ë‹¤ì´ì–´ê·¸ë¨", "ì„¤ê³„", "êµ¬ì¡°" ë“±ì´ í¬í•¨ë˜ê³  ìƒˆë¡œ ë§Œë“¤ì–´ë‹¬ë¼ëŠ” ìš”ì²­
- ì•„í‚¤í…ì²˜ ìˆ˜ì • ê´€ë ¨ í‚¤ì›Œë“œ: "ìˆ˜ì •", "ë³€ê²½", "ì—…ë°ì´íŠ¸", "ì¶”ê°€", "ì œê±°" ë“±ì´ ì•„í‚¤í…ì²˜ì™€ í•¨ê»˜ ì–¸ê¸‰
- ì¸í”„ë¼/ë°°í¬ ê´€ë ¨ í‚¤ì›Œë“œ: "ë°°í¬", "ì¸í”„ë¼", "Bicep", "bicep", "IaC" ë“±ì´ í¬í•¨

ì˜ˆì‹œ:
ì‚¬ìš©ì: "ì›¹ ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ìœ„í•œ Azure ì•„í‚¤í…ì²˜ë¥¼ ë§Œë“¤ì–´ì£¼ì„¸ìš”"
ì‘ë‹µ: {"response": "ì›¹ ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ìœ„í•œ Azure ì•„í‚¤í…ì²˜ ë‹¤ì´ì–´ê·¸ë¨ì„ ìƒì„±í•˜ê² ìŠµë‹ˆë‹¤.", "action": "generate_architecture_diagram"}

ì‚¬ìš©ì: "ê¸°ì¡´ ì•„í‚¤í…ì²˜ì— Redis ìºì‹œë¥¼ ì¶”ê°€í•´ì£¼ì„¸ìš”"  
ì‘ë‹µ: {"response": "ê¸°ì¡´ ì•„í‚¤í…ì²˜ì— Redis ìºì‹œë¥¼ ì¶”ê°€í•˜ì—¬ ìˆ˜ì •í•˜ê² ìŠµë‹ˆë‹¤.", "action": "modify_architecture_diagram"}

ì‚¬ìš©ì: "ì´ ì•„í‚¤í…ì²˜ë¥¼ ë°°í¬í•  Bicep ì½”ë“œë¥¼ ë§Œë“¤ì–´ì£¼ì„¸ìš”"
ì‘ë‹µ: {"response": "ì•„í‚¤í…ì²˜ë¥¼ ë°”íƒ•ìœ¼ë¡œ Bicep ì¸í”„ë¼ ì½”ë“œë¥¼ ìƒì„±í•˜ê² ìŠµë‹ˆë‹¤.", "action": "generate_bicep_infrastructure"}

ì‚¬ìš©ì: "Azureê°€ ë­ì•¼?"
ì‘ë‹µ: {"response": "AzureëŠ” Microsoftì—ì„œ ì œê³µí•˜ëŠ” í´ë¼ìš°ë“œ ì»´í“¨íŒ… í”Œë«í¼ì…ë‹ˆë‹¤...", "action": ""}

ë°˜ë“œì‹œ ìœ íš¨í•œ JSON í˜•íƒœë¡œë§Œ ì‘ë‹µí•´ì£¼ì„¸ìš”.
"""
    
    def initialize_chat_context(self, system_prompt: str, client_id: uuid.UUID) -> None:
        client_context = self.client_contexts[client_id]
        messages = client_context['messages']
        data_sources = client_context['data_sources']

        data_sources.clear()
        if (cognitive_search_endpoint and cognitive_search_api_key):
            data_source = {
                'type': 'azure_search',
                'parameters': {
                    'endpoint': cognitive_search_endpoint,
                    'index_name': cognitive_search_index_name,
                    'authentication': {
                        'type': 'api_key',
                        'key': cognitive_search_api_key
                    },
                    'semantic_configuration': '',
                    'query_type': 'simple',
                    'fields_mapping': {
                        'content_fields_separator': '\n',
                        'content_fields': ['content'],
                        'filepath_field': None,
                        'title_field': 'title',
                        'url_field': None
                    },
                    'in_scope': True,
                    'role_information': self.get_system_prompt()
                }
            }
            data_sources.append(data_source)

        messages.clear()
        if len(data_sources) == 0:
            system_message = {
                'role': 'system',
                'content': self.get_system_prompt()
            }
            messages.append(system_message)

    def handle_user_query(self, user_query: str, client_id: uuid.UUID, 
                         speak_callback=None) -> Generator[str, None, None]:
        client_context = self.client_contexts[client_id]
        messages = client_context['messages']
        data_sources = client_context['data_sources']

        chat_message = {
            'role': 'user',
            'content': user_query
        }

        messages.append(chat_message)

        if len(data_sources) > 0 and enable_quick_reply and speak_callback:
            speak_callback(random.choice(quick_replies), 2000, client_id)
        
        # í˜„ì¬ ì•„í‚¤í…ì²˜ êµ¬ì¡°ê°€ ìˆëŠ” ê²½ìš° ì»¨í…ìŠ¤íŠ¸ì— ì¶”ê°€
        current_structure = client_context.get('current_structure', '')
        if current_structure:
            architecture_context = f"""

í˜„ì¬ ì•„í‚¤í…ì²˜ êµ¬ì¡°ê°€ ìˆìŠµë‹ˆë‹¤: {current_structure}

ì‚¬ìš©ìê°€ ì•„í‚¤í…ì²˜ ìˆ˜ì •ì´ë‚˜ Bicep ì½”ë“œ ìƒì„±ì„ ìš”ì²­í•˜ë©´ ìœ„ êµ¬ì¡°ë¥¼ í™œìš©í•´ì£¼ì„¸ìš”."""
            
            chat_message['content'] += architecture_context
            logger.info(f"Added current structure context for client {client_id}")
        
        # LLMì—ì„œ JSON ì‘ë‹µ ë°›ê¸°
        response = azure_openai.chat.completions.create(
            model=azure_openai_deployment_name,
            messages=messages,
            extra_body={'data_sources': data_sources} if len(data_sources) > 0 else None
        )
        
        response_content = response.choices[0].message.content
        logger.info(f"LLM Response: {response_content}")
        
        try:
            # JSON ì‘ë‹µ íŒŒì‹±
            llm_response = json.loads(response_content)
            response_text = llm_response.get("response", "")
            action = llm_response.get("action", "")
            
            logger.info(f"Parsed response - action: {action}, response length: {len(response_text)}")
            
            # ì‘ë‹µ ë©”ì‹œì§€ë¥¼ ìŠ¤íŠ¸ë¦¬ë°ìœ¼ë¡œ ì¶œë ¥
            yield response_text + "\n\n"
            
            if speak_callback:
                speak_callback(response_text, 0, client_id)
            
            # actionì— ë”°ë¥¸ ë¶„ê¸° ì²˜ë¦¬
            if action == "generate_architecture_diagram":
                logger.info("Executing generate_architecture_diagram")
                yield "ğŸ” ì•„í‚¤í…ì²˜ ìš”êµ¬ì‚¬í•­ì„ ë¶„ì„í•˜ê³  ìˆìŠµë‹ˆë‹¤...\n\n"
                yield f"ğŸ“‹ ìš”êµ¬ì‚¬í•­: {user_query}\n\n"
                yield "ğŸ¨ Azure ì•„í‚¤í…ì²˜ ë‹¤ì´ì–´ê·¸ë¨ì„ ìƒì„± ì¤‘ì…ë‹ˆë‹¤...\n\n"
                
                if speak_callback:
                    speak_callback("ì•„í‚¤í…ì²˜ ë‹¤ì´ì–´ê·¸ë¨ì„ ìƒì„±í•˜ê³  ìˆìŠµë‹ˆë‹¤.", 0, client_id)
                
                result = self.architecture_service.generate_architecture_diagram(user_query)
                yield from self._handle_architecture_result(result, "generate", client_id, speak_callback)
                
            elif action == "modify_architecture_diagram":
                logger.info("Executing modify_architecture_diagram")
                yield "ğŸ”„ ê¸°ì¡´ ì•„í‚¤í…ì²˜ë¥¼ ë¶„ì„í•˜ê³  ìˆìŠµë‹ˆë‹¤...\n\n"
                yield f"ğŸ“ ìˆ˜ì • ìš”ì²­: {user_query}\n\n"
                yield "ğŸ¨ ì•„í‚¤í…ì²˜ ë‹¤ì´ì–´ê·¸ë¨ì„ ìˆ˜ì • ì¤‘ì…ë‹ˆë‹¤...\n\n"
                
                if speak_callback:
                    speak_callback("ì•„í‚¤í…ì²˜ ë‹¤ì´ì–´ê·¸ë¨ì„ ìˆ˜ì •í•˜ê³  ìˆìŠµë‹ˆë‹¤.", 0, client_id)
                
                if current_structure:
                    result = self.architecture_service.modify_architecture_diagram(current_structure, user_query)
                    yield from self._handle_architecture_result(result, "modify", client_id, speak_callback)
                else:
                    error_msg = "ìˆ˜ì •í•  ê¸°ì¡´ ì•„í‚¤í…ì²˜ê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ì•„í‚¤í…ì²˜ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”."
                    yield error_msg
                    if speak_callback:
                        speak_callback(error_msg, 0, client_id)
                        
            elif action == "generate_bicep_infrastructure":
                logger.info("Executing generate_bicep_infrastructure")
                yield "ğŸ”„ ì•„í‚¤í…ì²˜ êµ¬ì¡°ë¥¼ ë¶„ì„í•˜ê³  ìˆìŠµë‹ˆë‹¤...\n\n"
                yield "â˜ï¸ Azure Bicep ì¸í”„ë¼ ì½”ë“œë¥¼ ìƒì„± ì¤‘ì…ë‹ˆë‹¤...\n\n"
                yield "ğŸ“ ë°°í¬ ê°€ì´ë“œë¥¼ ì‘ì„±í•˜ê³  ìˆìŠµë‹ˆë‹¤...\n\n"
                
                if speak_callback:
                    speak_callback("ë¹„ì…‰ ì¸í”„ë¼ ì½”ë“œë¥¼ ìƒì„±í•˜ê³  ìˆìŠµë‹ˆë‹¤.", 0, client_id)
                
                if current_structure:
                    result = self.architecture_service.generate_bicep_infrastructure(current_structure)
                    yield from self._handle_bicep_result(result, client_id, speak_callback)
                else:
                    error_msg = "Bicep ì½”ë“œë¥¼ ìƒì„±í•  ì•„í‚¤í…ì²˜ê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ì•„í‚¤í…ì²˜ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”."
                    yield error_msg
                    if speak_callback:
                        speak_callback(error_msg, 0, client_id)
                        
            # actionì´ ë¹ˆ ë¬¸ìì—´ì¸ ê²½ìš° ì¼ë°˜ì ì¸ ì‘ë‹µë§Œ ì²˜ë¦¬ (ì´ë¯¸ ìœ„ì—ì„œ ì‘ë‹µ ì¶œë ¥ë¨)
            
            # ëŒ€í™” íˆìŠ¤í† ë¦¬ì— ì¶”ê°€
            assistant_message = {
                'role': 'assistant',
                'content': response_text
            }
            messages.append(assistant_message)
            
        except json.JSONDecodeError as e:
            logger.error(f"Failed to parse LLM response as JSON: {e}")
            logger.debug(f"Response content: {response_content}")
            
            # JSON íŒŒì‹± ì‹¤íŒ¨ ì‹œ ì¼ë°˜ì ì¸ ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µìœ¼ë¡œ í´ë°±
            yield "ì£„ì†¡í•©ë‹ˆë‹¤. ì‘ë‹µì„ ì²˜ë¦¬í•˜ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.\n\n"
            
            if speak_callback:
                speak_callback("ì‘ë‹µì„ ì²˜ë¦¬í•˜ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.", 0, client_id)
    
    def _handle_architecture_result(self, result: dict, operation_type: str, client_id: uuid.UUID, speak_callback=None) -> Generator[str, None, None]:
        """ì•„í‚¤í…ì²˜ ìƒì„±/ìˆ˜ì • ê²°ê³¼ ì²˜ë¦¬"""
        client_context = self.client_contexts[client_id]
        
        if result.get('success'):
            diagram_path = result['diagram_path']
            description = result['description']
            structure = result['structure']
            
            logger.info(f"Architecture {operation_type} successful: {diagram_path}")
            
            # í´ë¼ì´ì–¸íŠ¸ ì»¨í…ìŠ¤íŠ¸ì— í˜„ì¬ êµ¬ì¡° ì €ì¥
            client_context['current_structure'] = structure
            logger.info(f"Updated current_structure for client {client_id}")
            
            # ì™„ë£Œ ë©”ì‹œì§€
            if operation_type == "generate":
                yield "âœ… ë‹¤ì´ì–´ê·¸ë¨ ìƒì„±ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!\n\n"
                if speak_callback:
                    speak_callback("ë‹¤ì´ì–´ê·¸ë¨ ìƒì„±ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.", 0, client_id)
            elif operation_type == "modify":
                yield "âœ… ë‹¤ì´ì–´ê·¸ë¨ ìˆ˜ì •ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!\n\n"
                if speak_callback:
                    speak_callback("ë‹¤ì´ì–´ê·¸ë¨ ìˆ˜ì •ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.", 0, client_id)
            
            # ë‹¤ì´ì–´ê·¸ë¨ ê²½ë¡œì™€ êµ¬ì¡°ë¥¼ í´ë¼ì´ì–¸íŠ¸ì—ê²Œ ì „ì†¡
            yield f"<DIAGRAM>{diagram_path}</DIAGRAM>"
            yield f"<STRUCTURE>{structure}</STRUCTURE>"
            
            # ì„¤ëª…ì„ ìŠ¤íŠ¸ë¦¬ë°ìœ¼ë¡œ ì „ì†¡
            if description:
                spoken_sentence = ''
                for char in description:
                    yield char
                    if speak_callback and char in sentence_level_punctuations:
                        if spoken_sentence.strip():
                            speak_callback(spoken_sentence.strip(), 0, client_id)
                            spoken_sentence = ''
                    else:
                        spoken_sentence += char
                
                # ë§ˆì§€ë§‰ ë¬¸ì¥ ì²˜ë¦¬
                if spoken_sentence.strip() and speak_callback:
                    speak_callback(spoken_sentence.strip(), 0, client_id)
        else:
            # ì˜¤ë¥˜ ë°œìƒ ì‹œ
            error_message = f"ë‹¤ì´ì–´ê·¸ë¨ {operation_type} ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {result.get('error', 'Unknown error')}"
            logger.error(f"Architecture {operation_type} error: {result.get('error', 'Unknown error')}")
            yield error_message
            
            if speak_callback:
                speak_callback("ë‹¤ì´ì–´ê·¸ë¨ ì‘ì—… ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.", 0, client_id)
    
    def _handle_bicep_result(self, result: dict, client_id: uuid.UUID, speak_callback=None) -> Generator[str, None, None]:
        """Bicep ì½”ë“œ ìƒì„± ê²°ê³¼ ì²˜ë¦¬"""
        if result.get('success'):
            bicep_code = result.get('bicep_code', '')
            parameters_file = result.get('parameters_file', '')
            deployment_guide = result.get('deployment_guide', '')
            
            logger.info(f"Bicep code generated successfully: {len(bicep_code)} characters")
            
            # ì™„ë£Œ ë©”ì‹œì§€
            yield "âœ… Bicep ì¸í”„ë¼ ì½”ë“œ ìƒì„±ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!\n\n"
            
            if speak_callback:
                speak_callback("ë¹„ì…‰ ì¸í”„ë¼ ì½”ë“œ ìƒì„±ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.", 0, client_id)
            
            # Bicep ì½”ë“œ ì¶œë ¥
            if bicep_code:
                yield "## ğŸ“„ main.bicep\n\n"
                yield "```bicep\n"
                yield bicep_code
                yield "\n```\n\n"
            
            # íŒŒë¼ë¯¸í„° íŒŒì¼ ì¶œë ¥
            if parameters_file:
                yield "## âš™ï¸ main.bicepparam\n\n"
                yield "```bicepparam\n"
                yield parameters_file
                yield "\n```\n\n"
            
            # ë°°í¬ ê°€ì´ë“œ ì¶œë ¥
            if deployment_guide:
                yield deployment_guide
                
        else:
            # ì˜¤ë¥˜ ë°œìƒ ì‹œ
            error_message = f"Bicep ì½”ë“œ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {result.get('error', 'Unknown error')}"
            logger.error(f"Bicep generation error: {result.get('error', 'Unknown error')}")
            yield error_message
            
            if speak_callback:
                speak_callback("ë¹„ì…‰ ì½”ë“œ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.", 0, client_id)


chat_service = ChatService()
