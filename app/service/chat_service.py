import datetime
import json
import logging
import os
import pytz
import random
import re
import uuid
from openai import AzureOpenAI
from typing import Generator, Dict
from .architecture_diagram_service import ArchitectureDiagramService

azure_openai_endpoint = os.environ.get('AZURE_OPENAI_ENDPOINT')
azure_openai_api_key = os.environ.get('AZURE_OPENAI_API_KEY')
azure_openai_deployment_name = os.environ.get('AZURE_OPENAI_DEPLOYMENT_NAME')
cognitive_search_endpoint = os.environ.get('COGNITIVE_SEARCH_ENDPOINT')
cognitive_search_api_key = os.environ.get('COGNITIVE_SEARCH_API_KEY')
cognitive_search_index_name = os.environ.get('COGNITIVE_SEARCH_INDEX_NAME')

sentence_level_punctuations = ['.', '?', '!', ':', ';', 'ã€‚', 'ï¼Ÿ', 'ï¼', 'ï¼š', 'ï¼›']
enable_quick_reply = False
quick_replies = ['Let me take a look.', 'Let me check.', 'One moment, please.']
oyd_doc_regex = re.compile(r'\[doc(\d+)\]')

# Logger ì„¤ì •
logger = logging.getLogger(__name__)

azure_openai = None
if azure_openai_endpoint and azure_openai_api_key:
    azure_openai = AzureOpenAI(
        azure_endpoint=azure_openai_endpoint,
        api_version='2024-06-01',
        api_key=azure_openai_api_key)


class ChatService:
    
    def __init__(self):
        self.client_contexts = {}
        self.architecture_service = ArchitectureDiagramService()
    
    def set_client_contexts(self, client_contexts: Dict):
        self.client_contexts = client_contexts
    
    def get_architecture_diagram_tools(self):
        """Function Callingì„ ìœ„í•œ ì•„í‚¤í…ì²˜ ë‹¤ì´ì–´ê·¸ë¨ ë„êµ¬ ì •ì˜"""
        return [
            {
                "type": "function",
                "function": {
                    "name": "generate_architecture_diagram",
                    "description": "Azure ì•„í‚¤í…ì²˜ ìš”êµ¬ì‚¬í•­ì„ ë°›ì•„ì„œ Architecture Diagramì„ ìƒì„±í•©ë‹ˆë‹¤.",
                    "parameters": {
                        "type": "object",
                        "properties": {
                            "requirements": {
                                "type": "string",
                                "description": "ìì—°ì–´ë¡œ ì‘ì„±ëœ ì•„í‚¤í…ì²˜ ìš”êµ¬ì‚¬í•­"
                            }
                        },
                        "required": ["requirements"]
                    }
                }
            },
            {
                "type": "function",
                "function": {
                    "name": "modify_architecture_diagram",
                    "description": "ê¸°ì¡´ Architecture Diagramì„ ìˆ˜ì •í•©ë‹ˆë‹¤. ê¸°ì¡´ êµ¬ì¡°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë³€ê²½ ìš”ì²­ì„ ì ìš©í•©ë‹ˆë‹¤.",
                    "parameters": {
                        "type": "object",
                        "properties": {
                            "requirements": {
                                "type": "string",
                                "description": "ì•„í‚¤í…ì²˜ ìˆ˜ì • ìš”ì²­ì‚¬í•­ (ìì—°ì–´)"
                            },
                            "previous_structure": {
                                "type": "string",
                                "description": "ê¸°ì¡´ ì•„í‚¤í…ì²˜ êµ¬ì¡°ì˜ JSON ë¬¸ìì—´"
                            }
                        },
                        "required": ["requirements", "previous_structure"]
                    }
                }
            }
        ]
    
    def handle_function_call(self, function_name: str, arguments: dict):
        """Function Call ì²˜ë¦¬"""
        logger.info(f"Starting function call: {function_name}")
        logger.debug(f"Arguments received: {arguments}")
        
        if function_name == "generate_architecture_diagram":
            requirements = arguments.get("requirements", "")
            logger.info("Processing architecture diagram request")
            logger.debug(f"Requirements: {requirements}")
            
            try:
                result = self.architecture_service.generate_architecture_diagram(requirements)
                logger.info(f"Architecture service completed with success: {result.get('success', False)}")
                if result.get('success'):
                    logger.info(f"Generated diagram path: {result.get('diagram_path', 'N/A')}")
                else:
                    logger.error(f"Architecture service error: {result.get('error', 'Unknown error')}")
                return result
            except Exception as e:
                logger.exception(f"Exception occurred during architecture diagram generation: {str(e)}")
                return {"success": False, "error": f"Exception in architecture service: {str(e)}"}
        
        elif function_name == "modify_architecture_diagram":
            requirements = arguments.get("requirements", "")
            previous_structure = arguments.get("previous_structure", "")
            logger.info("Processing architecture diagram modification request")
            logger.debug(f"Modification request: {requirements}")
            logger.debug(f"Previous structure length: {len(previous_structure)} characters")
            
            try:
                result = self.architecture_service.modify_architecture_diagram(previous_structure, requirements)
                logger.info(f"Architecture modification completed with success: {result.get('success', False)}")
                if result.get('success'):
                    logger.info(f"Modified diagram path: {result.get('diagram_path', 'N/A')}")
                else:
                    logger.error(f"Architecture modification error: {result.get('error', 'Unknown error')}")
                return result
            except Exception as e:
                logger.exception(f"Exception occurred during architecture diagram modification: {str(e)}")
                return {"success": False, "error": f"Exception in architecture modification: {str(e)}"}
        else:
            logger.warning(f"Unknown function: {function_name}")
            return {"success": False, "error": f"Unknown function: {function_name}"}
    
    def initialize_chat_context(self, system_prompt: str, client_id: uuid.UUID) -> None:
        client_context = self.client_contexts[client_id]
        messages = client_context['messages']
        data_sources = client_context['data_sources']

        data_sources.clear()
        if (cognitive_search_endpoint and cognitive_search_api_key):
            data_source = {
                'type': 'azure_search',
                'parameters': {
                    'endpoint': cognitive_search_endpoint,
                    'index_name': cognitive_search_index_name,
                    'authentication': {
                        'type': 'api_key',
                        'key': cognitive_search_api_key
                    },
                    'semantic_configuration': '',
                    'query_type': 'simple',
                    'fields_mapping': {
                        'content_fields_separator': '\n',
                        'content_fields': ['content'],
                        'filepath_field': None,
                        'title_field': 'title',
                        'url_field': None
                    },
                    'in_scope': True,
                    'role_information': system_prompt
                }
            }
            data_sources.append(data_source)

        messages.clear()
        if len(data_sources) == 0:
            system_message = {
                'role': 'system',
                'content': system_prompt
            }
            messages.append(system_message)

    def handle_user_query(self, user_query: str, client_id: uuid.UUID, 
                         speak_callback=None) -> Generator[str, None, None]:
        client_context = self.client_contexts[client_id]
        messages = client_context['messages']
        data_sources = client_context['data_sources']

        chat_message = {
            'role': 'user',
            'content': user_query
        }

        messages.append(chat_message)

        if len(data_sources) > 0 and enable_quick_reply and speak_callback:
            speak_callback(random.choice(quick_replies), 2000, client_id)

        assistant_reply = ''
        tool_content = ''
        spoken_sentence = ''

        # Function Callingì„ ìœ„í•œ tools ì„¤ì •
        tools = self.get_architecture_diagram_tools()

        aoai_start_time = datetime.datetime.now(pytz.UTC)
        
        # ì•„í‚¤í…ì²˜ ìˆ˜ì • ìš”ì²­ì¸ì§€ í™•ì¸í•˜ê³  í˜„ì¬ êµ¬ì¡°ë¥¼ ë©”ì‹œì§€ì— ì¶”ê°€
        current_structure = client_context.get('current_structure', '')
        if current_structure and self._is_architecture_modification_request(user_query):
            # ì•„í‚¤í…ì²˜ ìˆ˜ì • ìš”ì²­ì¸ ê²½ìš° ì‹œìŠ¤í…œ ë©”ì‹œì§€ì— í˜„ì¬ êµ¬ì¡° ì •ë³´ ì¶”ê°€
            modification_context = f"""

í˜„ì¬ ì•„í‚¤í…ì²˜ êµ¬ì¡°ê°€ ìˆìŠµë‹ˆë‹¤. ì‚¬ìš©ìê°€ ì•„í‚¤í…ì²˜ ìˆ˜ì •ì„ ìš”ì²­í•˜ë©´, modify_architecture_diagram í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•  ë•Œ ë°˜ë“œì‹œ previous_structure íŒŒë¼ë¯¸í„°ì— ì•„ë˜ JSON êµ¬ì¡°ë¥¼ ì •í™•íˆ ì „ë‹¬í•´ì£¼ì„¸ìš”:

{current_structure}

ì‚¬ìš©ì ìš”ì²­ì„ ë°”íƒ•ìœ¼ë¡œ ì´ êµ¬ì¡°ë¥¼ ìˆ˜ì •í•˜ëŠ” modify_architecture_diagram í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•´ì£¼ì„¸ìš”."""
            
            chat_message['content'] += modification_context
            logger.info(f"Added current structure to modification request for client {client_id}")
        
        # ë¨¼ì € Function Callingì´ í•„ìš”í•œì§€ í™•ì¸
        response = azure_openai.chat.completions.create(
            model=azure_openai_deployment_name,
            messages=messages,
            tools=tools,
            tool_choice="auto",
            extra_body={'data_sources': data_sources} if len(data_sources) > 0 else None
        )
        
        response_message = response.choices[0].message
        
        # Function Callì´ ìš”ì²­ëœ ê²½ìš°
        if response_message.tool_calls:
            logger.info(f"{len(response_message.tool_calls)} tool call(s) detected for client {client_id}")
            
            for tool_call in response_message.tool_calls:
                function_name = tool_call.function.name
                function_args = json.loads(tool_call.function.arguments)
                
                logger.info(f"Executing function: {function_name}")
                logger.debug(f"Function arguments: {function_args}")
                
                # ì§„í–‰ ìƒí™© ì•Œë¦¼ ë©”ì‹œì§€ë“¤
                if function_name == "generate_architecture_diagram":
                    requirements = function_args.get("requirements", "")
                    
                    logger.info("Architecture diagram generation started")
                    logger.debug(f"Requirements: {requirements}")
                    
                    # ë‹¨ê³„ë³„ ì§„í–‰ ìƒí™© ë©”ì‹œì§€
                    yield "ğŸ” ì•„í‚¤í…ì²˜ ìš”êµ¬ì‚¬í•­ì„ ë¶„ì„í•˜ê³  ìˆìŠµë‹ˆë‹¤...\n\n"
                    yield f"ğŸ“‹ ìš”êµ¬ì‚¬í•­: {requirements}\n\n"
                    yield "ğŸ¨ Azure ì•„í‚¤í…ì²˜ ë‹¤ì´ì–´ê·¸ë¨ì„ ìƒì„± ì¤‘ì…ë‹ˆë‹¤...\n\n"
                    
                    if speak_callback:
                        speak_callback("ì•„í‚¤í…ì²˜ ë‹¤ì´ì–´ê·¸ë¨ì„ ìƒì„±í•˜ê³  ìˆìŠµë‹ˆë‹¤.", 0, client_id)
                
                elif function_name == "modify_architecture_diagram":
                    requirements = function_args.get("requirements", "")
                    previous_structure = function_args.get("previous_structure", "")
                    
                    logger.info("Architecture diagram modification started")
                    logger.debug(f"Modification request: {requirements}")
                    
                    # ë‹¨ê³„ë³„ ì§„í–‰ ìƒí™© ë©”ì‹œì§€
                    yield "ğŸ”„ ê¸°ì¡´ ì•„í‚¤í…ì²˜ë¥¼ ë¶„ì„í•˜ê³  ìˆìŠµë‹ˆë‹¤...\n\n"
                    yield f"ğŸ“ ìˆ˜ì • ìš”ì²­: {requirements}\n\n"
                    yield "ğŸ¨ ì•„í‚¤í…ì²˜ ë‹¤ì´ì–´ê·¸ë¨ì„ ìˆ˜ì • ì¤‘ì…ë‹ˆë‹¤...\n\n"
                    
                    if speak_callback:
                        speak_callback("ì•„í‚¤í…ì²˜ ë‹¤ì´ì–´ê·¸ë¨ì„ ìˆ˜ì •í•˜ê³  ìˆìŠµë‹ˆë‹¤.", 0, client_id)
                
                # ì•„í‚¤í…ì²˜ ë‹¤ì´ì–´ê·¸ë¨ ìƒì„± í•¨ìˆ˜ í˜¸ì¶œ
                logger.debug(f"Calling function handler for {function_name}")
                result = self.handle_function_call(function_name, function_args)
                logger.debug(f"Function result: {result}")
                
                if result['success']:
                    # ë‹¤ì´ì–´ê·¸ë¨ì´ ì„±ê³µì ìœ¼ë¡œ ìƒì„±ëœ ê²½ìš°
                    diagram_path = result['diagram_path']
                    description = result['description']
                    structure = result['structure']
                    
                    logger.info(f"Diagram processed successfully: {diagram_path}")
                    logger.debug(f"Description length: {len(description) if description else 0} characters")
                    
                    # ì™„ë£Œ ë©”ì‹œì§€
                    if function_name == "generate_architecture_diagram":
                        yield "âœ… ë‹¤ì´ì–´ê·¸ë¨ ìƒì„±ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!\n\n"
                        if speak_callback:
                            speak_callback("ë‹¤ì´ì–´ê·¸ë¨ ìƒì„±ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.", 0, client_id)
                    elif function_name == "modify_architecture_diagram":
                        yield "âœ… ë‹¤ì´ì–´ê·¸ë¨ ìˆ˜ì •ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!\n\n"
                        if speak_callback:
                            speak_callback("ë‹¤ì´ì–´ê·¸ë¨ ìˆ˜ì •ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.", 0, client_id)
                    
                    # ë‹¤ì´ì–´ê·¸ë¨ ê²½ë¡œì™€ ì„¤ëª…ì„ í´ë¼ì´ì–¸íŠ¸ì—ê²Œ ì „ì†¡
                    yield f"<DIAGRAM>{diagram_path}</DIAGRAM>"

                     # ë‹¤ì´ì–´ê·¸ë¨ ìŠ¤íŠ¸ëŸ­ì³ë¥¼ í´ë¼ì´ì–¸íŠ¸ì—ê²Œ ì „ì†¡
                    yield f"<STRUCTURE>{structure}</STRUCTURE>"
                    
                    # ì„¤ëª…ì„ ìŠ¤íŠ¸ë¦¬ë°ìœ¼ë¡œ ì „ì†¡
                    if description:
                        for char in description:
                            yield char
                            if speak_callback and char in sentence_level_punctuations:
                                if spoken_sentence.strip():
                                    speak_callback(spoken_sentence.strip(), 0, client_id)
                                    spoken_sentence = ''
                            else:
                                spoken_sentence += char
                    
                    # ë§ˆì§€ë§‰ ë¬¸ì¥ ì²˜ë¦¬
                    if spoken_sentence.strip() and speak_callback:
                        speak_callback(spoken_sentence.strip(), 0, client_id)
                    
                    assistant_reply = description
                else:
                    # ì˜¤ë¥˜ ë°œìƒ ì‹œ
                    if function_name == "generate_architecture_diagram":
                        error_message = f"ë‹¤ì´ì–´ê·¸ë¨ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {result.get('error', 'Unknown error')}"
                    elif function_name == "modify_architecture_diagram":
                        error_message = f"ë‹¤ì´ì–´ê·¸ë¨ ìˆ˜ì • ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {result.get('error', 'Unknown error')}"
                    else:
                        error_message = f"ì‘ì—… ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {result.get('error', 'Unknown error')}"
                    
                    logger.error(f"Function call error: {result.get('error', 'Unknown error')}")
                    yield error_message
                    assistant_reply = error_message
            
            logger.info(f"All function calls completed for client {client_id}")
        else:
            # ì¼ë°˜ì ì¸ ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ì²˜ë¦¬
            stream_response = azure_openai.chat.completions.create(
                model=azure_openai_deployment_name,
                messages=messages,
                extra_body={'data_sources': data_sources} if len(data_sources) > 0 else None,
                stream=True
            )

            is_first_chunk = True
            is_first_sentence = True
            for chunk in stream_response:
                if len(chunk.choices) > 0:
                    response_token = chunk.choices[0].delta.content
                    if response_token is not None:
                        if is_first_chunk:
                            first_token_latency_ms = round(
                                (datetime.datetime.now(pytz.UTC) - aoai_start_time).total_seconds() * 1000)
                            logger.info(f"AOAI first token latency: {first_token_latency_ms}ms")
                            yield f"<FTL>{first_token_latency_ms}</FTL>"
                            is_first_chunk = False
                        if oyd_doc_regex.search(response_token):
                            response_token = oyd_doc_regex.sub('', response_token).strip()
                        yield response_token
                        assistant_reply += response_token
                        if response_token == '\n' or response_token == '\n\n':
                            if is_first_sentence:
                                first_sentence_latency_ms = round(
                                    (datetime.datetime.now(pytz.UTC) - aoai_start_time).total_seconds() * 1000)
                                logger.info(f"AOAI first sentence latency: {first_sentence_latency_ms}ms")
                                yield f"<FSL>{first_sentence_latency_ms}</FSL>"
                                is_first_sentence = False
                            if speak_callback:
                                speak_callback(spoken_sentence.strip(), 0, client_id)
                            spoken_sentence = ''
                        else:
                            response_token = response_token.replace('\n', '')
                            spoken_sentence += response_token
                            if len(response_token) == 1 or len(response_token) == 2:
                                for punctuation in sentence_level_punctuations:
                                    if response_token.startswith(punctuation):
                                        if is_first_sentence:
                                            first_sentence_latency_ms = round(
                                                (datetime.datetime.now(pytz.UTC) - aoai_start_time).total_seconds() * 1000)
                                            logger.info(f"AOAI first sentence latency: {first_sentence_latency_ms}ms")
                                            yield f"<FSL>{first_sentence_latency_ms}</FSL>"
                                            is_first_sentence = False
                                        if speak_callback:
                                            speak_callback(spoken_sentence.strip(), 0, client_id)
                                        spoken_sentence = ''
                                        break

            if spoken_sentence != '' and speak_callback:
                speak_callback(spoken_sentence.strip(), 0, client_id)
                spoken_sentence = ''

        if len(data_sources) > 0:
            tool_message = {
                'role': 'tool',
                'content': tool_content
            }
            messages.append(tool_message)

        assistant_message = {
            'role': 'assistant',
            'content': assistant_reply
        }
        messages.append(assistant_message)

    def _is_architecture_modification_request(self, user_query: str) -> bool:
        """ì‚¬ìš©ì ì¿¼ë¦¬ê°€ ì•„í‚¤í…ì²˜ ìˆ˜ì • ìš”ì²­ì¸ì§€ í™•ì¸í•©ë‹ˆë‹¤."""
        modification_keywords = [
            'ìˆ˜ì •', 'ë³€ê²½', 'ì—…ë°ì´íŠ¸', 'ê°œì„ ', 'ì¶”ê°€', 'ì œê±°', 'ì‚­ì œ', 
            'modify', 'change', 'update', 'improve', 'add', 'remove', 'delete',
            'ë°”ê¿”', 'ê³ ì³', 'ìˆ˜ì •í•´', 'ë³€ê²½í•´', 'ì—…ë°ì´íŠ¸í•´', 'ê°œì„ í•´', 'ì¶”ê°€í•´', 'ì œê±°í•´', 'ì‚­ì œí•´'
        ]
        architecture_keywords = [
            'ì•„í‚¤í…ì²˜', 'êµ¬ì¡°', 'ë‹¤ì´ì–´ê·¸ë¨', 'ì„¤ê³„', 
            'architecture', 'diagram', 'structure', 'design'
        ]
        
        query_lower = user_query.lower()
        has_modification = any(keyword in query_lower for keyword in modification_keywords)
        has_architecture = any(keyword in query_lower for keyword in architecture_keywords)
        
        return has_modification and has_architecture


chat_service = ChatService()
